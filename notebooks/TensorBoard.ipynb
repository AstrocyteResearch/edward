{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TensorBoard\n",
    "\n",
    "This example uses the 'supervised-regression' tutorial to show how to use TensorBoard with Edward\n",
    "\n",
    "See the original tutorial here: http://edwardlib.org/tutorials/supervised-regression.\n",
    "\n",
    "To integrate TensorBoard with Edward we are taking best practices from here:\n",
    "https://www.tensorflow.org/get_started/graph_viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "To use TensorBoard we need to send tensorflow logs to a specific directory and we need to have a tensorboard server running in a the same director or a parent directory.\n",
    "\n",
    "**Launch TensorBoard**\n",
    "```bash\n",
    "   python -m tensorflow.tensorboard --logdir=/data/tensorflow/logs --host=localhost\n",
    "```\n",
    "Then open http://localhost:6006\n",
    "\n",
    "To make TensorBoard work well, we need to ensure we have proper **directory naming** and **variable naming**\n",
    "\n",
    "\n",
    "### Directory Naming\n",
    "The following variables are set when either calling `inference.initialize` or `inference.run`\n",
    "\n",
    " * `logdir`: the parent directory where all logs for this particular analysis should go\n",
    " * `logrun`: the name of the subdirectory to store variables for the specific estimation run we are running.\n",
    "    * This is needed to help TensorBoard compare data against different estimations or configurations of the model, \n",
    "    * If `logrun` is set to None, then the model will use the current UTC timestamp 'YYYYMMDDTHHMMSS\"\n",
    "       \n",
    "### Variable Naming\n",
    "Each TensorFlow variable has a unique name and the TensorBoard organizes itself based on the names of variables.\n",
    "\n",
    "  * **Name and Variable Scopeing**:  See the usage below to help prefix variable names based on how they are used\n",
    "  * **Forward Slashes**:  To define variables that are children of others, uses a forward slash. For example the Normal variable 'weight' might have priors called 'weight_loc' and 'weight_scale'\n",
    "  \n",
    "### Logging Automatically enabled\n",
    "\n",
    "Once you have specified `logdir` and optionally `logrun` in `inference.run`, at various points in the training, the values of the named latent_variables in your model will be saved to TensorBoard.  To provide a custom list of variables pass the list in the parameter `logvars`.\n",
    "\n",
    "See the source `edward/inference/inference.py` for more information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Supervised Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data\n",
    "\n",
    "Simulate training and test sets of $40$ data points. They comprise of\n",
    "pairs of inputs $\\mathbf{x}_n\\in\\mathbb{R}^{5}$ and outputs\n",
    "$y_n\\in\\mathbb{R}$. They have a linear dependence with normally\n",
    "distributed noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_toy_dataset(N, w):\n",
    "  D = len(w)\n",
    "  x = np.random.normal(0.0, 2.0, size=(N, D))\n",
    "  y = np.dot(x, w) + np.random.normal(0.0, 0.01, size=N)\n",
    "  return x, y\n",
    "\n",
    "#ed.set_seed(42)\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 5  # number of features\n",
    "\n",
    "# Variable scope adds this prefix to all data regardless if keyword 'name' is set\n",
    "with tf.variable_scope('data'): \n",
    "    w_true = np.random.randn(D) * 0.5\n",
    "    X_train, y_train = build_toy_dataset(N, w_true)\n",
    "    X_test, y_test = build_toy_dataset(N, w_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model\n",
    "\n",
    "Posit the model as Bayesian linear regression (Murphy, 2012).\n",
    "It assumes a linear relationship between the inputs\n",
    "$\\mathbf{x}\\in\\mathbb{R}^D$ and the outputs $y\\in\\mathbb{R}$.\n",
    "\n",
    "For a set of $N$ data points $(\\mathbf{X},\\mathbf{y})=\\{(\\mathbf{x}_n, y_n)\\}$,\n",
    "the model posits the following distributions:\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{w})\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{w} \\mid \\mathbf{0}, \\sigma_w^2\\mathbf{I}),\n",
    "  \\\\[1.5ex]\n",
    "  p(b)\n",
    "  &=\n",
    "  \\text{Normal}(b \\mid 0, \\sigma_b^2),\n",
    "  \\\\\n",
    "  p(\\mathbf{y} \\mid \\mathbf{w}, b, \\mathbf{X})\n",
    "  &=\n",
    "  \\prod_{n=1}^N\n",
    "  \\text{Normal}(y_n \\mid \\mathbf{x}_n^\\top\\mathbf{w} + b, \\sigma_y^2).\n",
    "\\end{align*}\n",
    "\n",
    "The latent variables are the linear model's weights $\\mathbf{w}$ and\n",
    "intercept $b$, also known as the bias.\n",
    "Assume $\\sigma_w^2,\\sigma_b^2$ are known prior variances and $\\sigma_y^2$ is a\n",
    "known likelihood variance. The mean of the likelihood is given by a\n",
    "linear transformation of the inputs $\\mathbf{x}_n$.\n",
    "\n",
    "Let's build the model in Edward, fixing $\\sigma_w,\\sigma_b,\\sigma_y=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Name scope only adds this prefix to names where keyword 'name' is set\n",
    "with tf.name_scope('model'): \n",
    "    X = tf.placeholder(tf.float32, [N, D], name=\"X\")\n",
    "    w = Normal(loc=tf.zeros(D, name=\"weights/loc\"), scale=tf.ones(D, name=\"weights/loc\"), name=\"weights\")\n",
    "    b = Normal(loc=tf.zeros(1, name=\"bias/loc\"), scale=tf.ones(1, name=\"bias/scale\"), name=\"bias\")\n",
    "    y = Normal(loc=ed.dot(X, w) + b, scale=tf.ones(N, name=\"y/scale\"), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, we define a placeholder `X`. During inference, we pass in\n",
    "the value for this placeholder according to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inference\n",
    "\n",
    "We now turn to inferring the posterior using variational inference.\n",
    "Define the variational model to be a fully factorized normal across\n",
    "the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [100%] ██████████████████████████████ Elapsed: 10s | Loss: 52.302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('posterior'):\n",
    "    qw = Normal(loc=tf.Variable(tf.random_normal([D]), name=\"qw/loc\"),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([D])), name=\"qw/scale\"), name=\"qw\")\n",
    "    qb = Normal(loc=tf.Variable(tf.random_normal([1]), name=\"qb/loc\"),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random_normal([1])), name=\"qb/scale\"), name=\"qb\")\n",
    "\n",
    "with tf.name_scope('inference'):\n",
    "    inference = ed.KLqp({w: qw, b: qb}, data={X: X_train, y: y_train})   \n",
    "    inference.run(n_samples=5, n_iter=250, logdir='C:\\\\Users\\\\skruz\\\\temp\\\\tensorflow\\\\LR', logrun=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "Goto Running TensorBoard:  http://localhost:6006\n",
    "\n",
    "See Screenshots of what this looks like in:\n",
    "\n",
    " * <a href=\"https://github.com/blei-lab/edward/tree/master/docs/images/tensorboard_scalars.PNG\">docs/images/tensorboard_scalars.PNG</a>\n",
    " * <a href=\"https://github.com/blei-lab/edward/tree/master/docs/images/tensorboard_distributions.PNG\">docs/images/tensorboard_distributions.PNG</a>\n",
    " * <a href=\"https://github.com/blei-lab/edward/tree/master/docs/images/tensorboard_histograms.PNG\">docs/images/tensorboard_histograms.PNG</a>\n",
    " * <a href=\"https://github.com/blei-lab/edward/tree/master/docs/images/tensorboard_graphs.PNG\">docs/images/tensorboard_graphs.PNG</a>\n",
    " * <a href=\"https://github.com/blei-lab/edward/tree/master/docs/images/tensorboard_graph1.PNG\">docs/images/tensorboard_graph1.PNG</a>\n",
    " \n",
    "** Thank you - Author: Sean Kruzel (closedLoop) - Astrocyte Research 2017 **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
